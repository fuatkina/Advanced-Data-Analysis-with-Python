{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mature-ozone",
   "metadata": {},
   "source": [
    "## Spider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8242b6-f9fd-4cd6-99ef-451bb735bfca",
   "metadata": {},
   "source": [
    "Spider works faster when we want to download a large number of pages. Let's take a brief look at the objects we call classes. Being an object-oriented programming language, nearly everything in Python is designed as a class. The class is a very important tool for programming in that it can create instances from itself and run nested functions. Various properties and methods can be assigned to classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f56cf-abd1-4e6f-be70-3b6be308def3",
   "metadata": {},
   "source": [
    "#### How does it work?\n",
    "\n",
    "In the code below you can define a class named IMDB_Spider. This class runs the Spider method of the scrapy library. The ``start_requests`` function in the content serves to start the process first. At this stage, you can define the first page from which the download will start. Then, make the necessary intervention on the ``self`` parameter that will be modified throughout the class and introduced from the function to the function, and pass to the next function (```parse_front````).\n",
    "\n",
    "With the ```parse_front``` function, you can now define, open and store your Xpaths to be used in certain lists. At this stage, create your links that you want to progress. You can move these links to the next function using the command below.\n",
    "\n",
    "```yield response.follow(url = url, callback = self.parse_pages)```\n",
    "\n",
    "Now you have come to the ``parse_pages`` function. This function will perform the action you specified for each URL that you created and forwarded in the previous step. So you can define an Xpath again and mark the data you want to pull. Then leave the class by keeping the downloaded data.\n",
    "\n",
    "In order to run the class you have defined, you need to call it:\n",
    "\n",
    "\n",
    "```process = CrawlerProcess()```\n",
    "\n",
    "```process.crawl(IMDB_Spider)```\n",
    "\n",
    "```process.start()```\n",
    "\n",
    "Don't forget to define empty lists before doing this because you will be writing your downloaded data into these empty lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class IMDB_Spider(scrapy.Spider):\n",
    "    name = \"IMDB_Spider\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(url = 'https://m.imdb.com/chart/top', callback = self.parse_front)\n",
    "\n",
    "    def parse_front(self, response):\n",
    "        \n",
    "        movie_names = response.xpath('//h4/text()').extract()\n",
    "        for item in movie_names:\n",
    "            cleaned_string = item.strip()\n",
    "            if cleaned_string != '':\n",
    "                movie_list.append(cleaned_string)\n",
    "        \n",
    "        movie_years = response.xpath('//h4/span[2]/text()').extract()\n",
    "        for item in movie_years:\n",
    "                years.append(item)\n",
    "\n",
    "        movie_links = response.xpath('//*[@id=\"chart-content\"]/div/div/div/a/@href').extract()\n",
    "        for item in movie_links:\n",
    "            first_part_url = 'https://m.imdb.com'\n",
    "            last_part_url = '?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=df09bbba-7a44-41c0-bc85-426ba05a5574&pf_rd_r=R9N3Q0473JZET8YH4S2A&pf_rd_s=top-1&pf_rd_t=15506&pf_rd_i=top&ref_=m_chttp_tt_1'\n",
    "            url = first_part_url + item + last_part_url\n",
    "            links.append(url)\n",
    "            yield response.follow(url = url,  callback = self.parse_pages)\n",
    "            \n",
    "    def parse_pages(self, response):\n",
    "        movie_players = response.xpath('//*[@id=\"__next\"]/main/div/section[1]/div/section/div/div[1]/section[4]/div[2]/div[2]/div/div[2]/a/text()').extract()\n",
    "        players_list.append(movie_players)\n",
    "\n",
    "\n",
    "movie_list = []\n",
    "years = []\n",
    "links = []\n",
    "players_list = []\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(IMDB_Spider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf3e6e-52a6-44c6-8847-c8a63700b9be",
   "metadata": {},
   "source": [
    "### Display first five lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1657a43-8456-4436-bdb5-1f9c1cb6712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "links[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f49b430-091b-4307-b936-94601bb5612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "years[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a6e1e-0c73-4c77-98bd-f52d903ea2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_list[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c2b38-a337-4574-abb9-c6cdb990d298",
   "metadata": {},
   "source": [
    "### First dataframe, then csv or json\n",
    "\n",
    "Convert your data into a dictionary, then into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dictimdb = {'movie name':movie_list, 'year':years, 'link':links, 'player_list': players_list}\n",
    "data_imdb = pd.DataFrame(dictimdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0a882-ed9b-430c-b374-7930425c324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imdb['player_list'][56]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a079d-7c5f-4e2a-b35f-0e92d21f0613",
   "metadata": {},
   "source": [
    "Now you can save the relevant data to your computer as a csv or json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beacb402-4e23-4a43-b147-22bd194c3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imdb.to_csv(\"IMDB_Filmlerim.csv\")\n",
    "data_imdb.to_json(\"IMDB_Filmlerim.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
